# Text Generation with a Transformer Decoder Network

We train a transformer to predict the next character of a sentence. The model is trained on a reduced set of the works of William Shakespeare.